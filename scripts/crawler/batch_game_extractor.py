# scripts/crawler/batch_game_extractor.py
# å¤šçº¿ç¨‹æ‰¹é‡æ¸¸æˆæ•°æ®æå–å™¨ - ä½¿ç”¨6çº¿ç¨‹å¹¶å‘å¤„ç†æ¸¸æˆè¯¦æƒ…é¡µé¢æ•°æ®æå–

import json
import os
import time
import random
import threading
import argparse
import sys
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from game_detail_extractor import GameDetailExtractor

class BatchGameExtractor:
    """æ‰¹é‡æ¸¸æˆæ•°æ®æå–å™¨
    
    ä½¿ç”¨å¤šçº¿ç¨‹å¹¶å‘æå–æ¸¸æˆè¯¦æƒ…æ•°æ®ï¼Œæ”¯æŒè¿›åº¦ç›‘æ§ã€é”™è¯¯å¤„ç†å’Œæ–­ç‚¹ç»­ä¼ 
    """
    
    def __init__(self, max_workers=6, delay_range=(1, 3), output_dir="../output"):
        """
        åˆå§‹åŒ–æ‰¹é‡æå–å™¨
        
        Args:
            max_workers (int): æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°ï¼Œé»˜è®¤6
            delay_range (tuple): è¯·æ±‚å»¶è¿ŸèŒƒå›´(ç§’)ï¼Œé»˜è®¤1-3ç§’
            output_dir (str): è¾“å‡ºç›®å½•è·¯å¾„
        """
        self.max_workers = max_workers
        self.delay_range = delay_range
        self.output_dir = output_dir
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.success_count = 0
        self.error_count = 0
        self.total_count = 0
        self.start_time = None
        
        # çº¿ç¨‹é”
        self.lock = threading.Lock()
        
        # ç»“æœå­˜å‚¨
        self.results = []
        self.errors = []
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
    
    def load_games_list(self, file_path):
        """
        åŠ è½½æ¸¸æˆåˆ—è¡¨æ•°æ®
        
        Args:
            file_path (str): æ¸¸æˆåˆ—è¡¨JSONæ–‡ä»¶è·¯å¾„
            
        Returns:
            list: æ¸¸æˆä¿¡æ¯åˆ—è¡¨
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('games', [])
        except Exception as e:
            print(f"âŒ åŠ è½½æ¸¸æˆåˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def find_game_index_by_name(self, games_list, game_name):
        """
        æ ¹æ®æ¸¸æˆåç§°æŸ¥æ‰¾åœ¨åˆ—è¡¨ä¸­çš„ç´¢å¼•ä½ç½®
        
        Args:
            games_list (list): æ¸¸æˆåˆ—è¡¨
            game_name (str): æ¸¸æˆåç§°
            
        Returns:
            int: æ¸¸æˆç´¢å¼•ï¼Œæœªæ‰¾åˆ°è¿”å›-1
        """
        for i, game in enumerate(games_list):
            if game.get('name') == game_name:
                return i
        return -1
    
    def load_existing_results(self, main_result_file):
        """
        åŠ è½½å·²å­˜åœ¨çš„ç»“æœæ–‡ä»¶ï¼Œè¿”å›å·²å¤„ç†çš„æ¸¸æˆåç§°é›†åˆ
        
        Args:
            main_result_file (str): ä¸»ç»“æœæ–‡ä»¶è·¯å¾„
            
        Returns:
            tuple: (å·²å¤„ç†æ¸¸æˆåç§°é›†åˆ, ç°æœ‰ç»“æœåˆ—è¡¨)
        """
        if not os.path.exists(main_result_file):
            return set(), []
        
        try:
            with open(main_result_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                processed_games = set()
                existing_results = data.get('games', [])
                
                for game in existing_results:
                    if 'basic_info' in game and 'name' in game['basic_info']:
                        processed_games.add(game['basic_info']['name'])
                
                return processed_games, existing_results
        except Exception as e:
            print(f"âš ï¸ åŠ è½½ç°æœ‰ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
            return set(), []
    
    def extract_single_game(self, game_info, thread_id):
        """
        æå–å•ä¸ªæ¸¸æˆçš„è¯¦æƒ…æ•°æ®
        
        Args:
            game_info (dict): æ¸¸æˆåŸºæœ¬ä¿¡æ¯
            thread_id (int): çº¿ç¨‹ID
            
        Returns:
            dict or None: æå–ç»“æœæˆ–None(å¤±è´¥æ—¶)
        """
        try:
            # éšæœºå»¶è¿Ÿé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            delay = random.uniform(*self.delay_range)
            time.sleep(delay)
            
            # åˆ›å»ºæå–å™¨å®ä¾‹(æ— å¤´æ¨¡å¼)
            extractor = GameDetailExtractor(headless=True)
            
            # æå–æ¸¸æˆè¯¦æƒ… - ä¿®å¤ï¼šä¼ é€’ä¸¤ä¸ªå‚æ•°
            result = extractor.extract_game_details(game_info['url'], game_info)
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            with self.lock:
                self.success_count += 1
                progress = (self.success_count + self.error_count) / self.total_count * 100
                elapsed = time.time() - self.start_time
                avg_time = elapsed / (self.success_count + self.error_count)
                remaining = (self.total_count - self.success_count - self.error_count) * avg_time
                
                print(f"âœ… [çº¿ç¨‹{thread_id}] {game_info['name']} | "
                      f"è¿›åº¦: {self.success_count + self.error_count}/{self.total_count} ({progress:.1f}%) | "
                      f"æˆåŠŸ: {self.success_count} | å¤±è´¥: {self.error_count} | "
                      f"é¢„è®¡å‰©ä½™: {remaining/60:.1f}åˆ†é’Ÿ")
            
            return result
            
        except Exception as e:
            # è®°å½•é”™è¯¯
            error_info = {
                'game': game_info,
                'error': str(e),
                'timestamp': datetime.now().isoformat(),
                'thread_id': thread_id
            }
            
            with self.lock:
                self.error_count += 1
                self.errors.append(error_info)
                progress = (self.success_count + self.error_count) / self.total_count * 100
                print(f"âŒ [çº¿ç¨‹{thread_id}] {game_info['name']} å¤±è´¥: {str(e)} | "
                      f"è¿›åº¦: {self.success_count + self.error_count}/{self.total_count} ({progress:.1f}%)")
            
            return None
    
    def save_unified_results(self, all_results, result_file_path):
        """
        ä¿å­˜ç»Ÿä¸€çš„ç»“æœæ–‡ä»¶
        
        Args:
            all_results (list): æ‰€æœ‰ç»“æœåˆ—è¡¨
            result_file_path (str): ç»“æœæ–‡ä»¶è·¯å¾„
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        result_data = {
            "metadata": {
                "total_games": len(all_results),
                "last_updated": timestamp,
                "extraction_info": {
                    "success_count": len([r for r in all_results if r.get('success', False)]),
                    "total_processed": len(all_results)
                }
            },
            "games": all_results
        }
        
        with open(result_file_path, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {result_file_path}")
    
    def batch_extract_with_resume(self, games_list, start_game_name=None, 
                                 main_result_file="all_games_extracted.json",
                                 batch_size=300, rest_minutes=1):
        """
        æ”¯æŒæŒ‰æ¸¸æˆåç§°æ–­ç‚¹ç»­ä¼ çš„æ‰¹é‡æå–ï¼Œæ¯å¤„ç†batch_sizeä¸ªæ¸¸æˆä¼‘æ¯rest_minutesåˆ†é’Ÿ
        
        Args:
            games_list (list): æ¸¸æˆåˆ—è¡¨
            start_game_name (str): å¼€å§‹æ¸¸æˆåç§°ï¼ŒNoneè¡¨ç¤ºä»å¤´å¼€å§‹
            main_result_file (str): ä¸»ç»“æœæ–‡ä»¶å
            batch_size (int): æ¯æ‰¹å¤„ç†çš„æ¸¸æˆæ•°é‡
            rest_minutes (int): æ¯æ‰¹ä¹‹é—´çš„ä¼‘æ¯æ—¶é—´(åˆ†é’Ÿ)
        """
        # æ„å»ºå®Œæ•´çš„ç»“æœæ–‡ä»¶è·¯å¾„
        result_file_path = os.path.join(self.output_dir, main_result_file)
        
        # åŠ è½½å·²å¤„ç†çš„æ¸¸æˆ
        processed_games, existing_results = self.load_existing_results(result_file_path)
        print(f"ğŸ“‹ å·²å¤„ç†æ¸¸æˆæ•°é‡: {len(processed_games)}")
        
        # ç¡®å®šå¼€å§‹ä½ç½®
        start_index = 0
        if start_game_name:
            start_index = self.find_game_index_by_name(games_list, start_game_name)
            if start_index == -1:
                print(f"âŒ æœªæ‰¾åˆ°æ¸¸æˆ: {start_game_name}")
                return []
            print(f"ğŸ¯ ä»æ¸¸æˆ '{start_game_name}' å¼€å§‹ (ç´¢å¼•: {start_index})")
        
        # è¿‡æ»¤æ‰å·²å¤„ç†çš„æ¸¸æˆ
        games_to_process = []
        for i in range(start_index, len(games_list)):
            game = games_list[i]
            if game.get('name') not in processed_games:
                games_to_process.append(game)
            else:
                print(f"â­ï¸ è·³è¿‡å·²å¤„ç†æ¸¸æˆ: {game.get('name')}")
        
        if not games_to_process:
            print("âœ… æ‰€æœ‰æ¸¸æˆéƒ½å·²å¤„ç†å®Œæˆï¼")
            return existing_results
        
        print(f"ğŸš€ éœ€è¦å¤„ç† {len(games_to_process)} ä¸ªæ–°æ¸¸æˆ")
        print(f"ğŸ“Š é…ç½®: {self.max_workers} çº¿ç¨‹, æ¯{batch_size}ä¸ªæ¸¸æˆä¼‘æ¯{rest_minutes}åˆ†é’Ÿ")
        print("-" * 80)
        
        # åˆ†æ‰¹å¤„ç†
        all_new_results = []
        total_batches = (len(games_to_process) + batch_size - 1) // batch_size
        
        for batch_num in range(total_batches):
            start_idx = batch_num * batch_size
            end_idx = min(start_idx + batch_size, len(games_to_process))
            current_batch = games_to_process[start_idx:end_idx]
            
            print(f"\nğŸ”„ å¤„ç†ç¬¬ {batch_num + 1}/{total_batches} æ‰¹ ({len(current_batch)} ä¸ªæ¸¸æˆ)")
            
            # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
            self.success_count = 0
            self.error_count = 0
            self.total_count = len(current_batch)
            self.start_time = time.time()
            self.results = []
            self.errors = []
            
            # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå½“å‰æ‰¹æ¬¡
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                future_to_game = {
                    executor.submit(self.extract_single_game, game, i % self.max_workers + 1): game 
                    for i, game in enumerate(current_batch)
                }
                
                # æ”¶é›†ç»“æœ
                for future in as_completed(future_to_game):
                    result = future.result()
                    if result:
                        all_new_results.append(result)
            
            # è¾“å‡ºæ‰¹æ¬¡ç»Ÿè®¡
            duration = time.time() - self.start_time
            print(f"ğŸ“Š ç¬¬{batch_num + 1}æ‰¹å®Œæˆ: æˆåŠŸ{self.success_count} | å¤±è´¥{self.error_count} | è€—æ—¶{duration/60:.1f}åˆ†é’Ÿ")
            
            # ä¿å­˜å½“å‰è¿›åº¦åˆ°ä¸»æ–‡ä»¶
            current_all_results = existing_results + all_new_results
            self.save_unified_results(current_all_results, result_file_path)
            
            # å¦‚æœä¸æ˜¯æœ€åä¸€æ‰¹ï¼Œä¼‘æ¯æŒ‡å®šæ—¶é—´
            if batch_num < total_batches - 1:
                print(f"ğŸ˜´ ä¼‘æ¯ {rest_minutes} åˆ†é’Ÿ...")
                time.sleep(rest_minutes * 60)
        
        print("\nğŸ‰ å…¨éƒ¨æ‰¹æ¬¡å¤„ç†å®Œæˆï¼")
        final_results = existing_results + all_new_results
        print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡: æ€»è®¡{len(final_results)}ä¸ªæ¸¸æˆ | æ–°å¢{len(all_new_results)}ä¸ª")
        
        return final_results

def main():
    """
    ä¸»å‡½æ•° - æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    
    ä½¿ç”¨æ–¹æ³•:
    python batch_game_extractor.py                    # ä»å¤´å¼€å§‹
    python batch_game_extractor.py --start "æ¸¸æˆåç§°"  # ä»æŒ‡å®šæ¸¸æˆå¼€å§‹
    """
    parser = argparse.ArgumentParser(description='æ‰¹é‡æ¸¸æˆæ•°æ®æå–å™¨')
    parser.add_argument('--start', type=str, help='å¼€å§‹æ¸¸æˆåç§°ï¼Œä¸æŒ‡å®šåˆ™ä»å¤´å¼€å§‹')
    parser.add_argument('--workers', type=int, default=6, help='çº¿ç¨‹æ•°ï¼Œé»˜è®¤6')
    parser.add_argument('--batch-size', type=int, default=300, help='æ¯æ‰¹å¤„ç†æ¸¸æˆæ•°é‡ï¼Œé»˜è®¤300')
    parser.add_argument('--rest-minutes', type=int, default=1, help='æ¯æ‰¹ä¹‹é—´ä¼‘æ¯æ—¶é—´(åˆ†é’Ÿ)ï¼Œé»˜è®¤1')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæå–å™¨å®ä¾‹
    extractor = BatchGameExtractor(
        max_workers=args.workers,
        delay_range=(1, 3),
        output_dir="../output"
    )
    
    # åŠ è½½æ¸¸æˆåˆ—è¡¨
    games_list = extractor.load_games_list("../output/all_games_continuous.json")
    
    if not games_list:
        print("âŒ æœªæ‰¾åˆ°æ¸¸æˆåˆ—è¡¨æ•°æ®")
        return
    
    print(f"ğŸ“‹ åŠ è½½åˆ° {len(games_list)} ä¸ªæ¸¸æˆ")
    
    if args.start:
        print(f"ğŸ¯ ä»æ¸¸æˆ '{args.start}' å¼€å§‹å¤„ç†")
    else:
        print("ğŸš€ ä»å¤´å¼€å§‹å¤„ç†æ‰€æœ‰æ¸¸æˆ")
    
    # å¼€å§‹æ‰¹é‡æå–
    extractor.batch_extract_with_resume(
        games_list=games_list,
        start_game_name=args.start,
        main_result_file="all_games_extracted.json",
        batch_size=args.batch_size,
        rest_minutes=args.rest_minutes
    )

if __name__ == "__main__":
    main()