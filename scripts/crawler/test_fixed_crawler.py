# scripts/crawler/test_fixed_crawler.py - æµ‹è¯•ä¿®å¤åçš„çˆ¬è™«
"""
ä½¿ç”¨ä¿®å¤åçš„çˆ¬è™«é‡‡é›†å°‘é‡æ¸¸æˆè¿›è¡ŒéªŒè¯
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from gamemonetize_enhanced_crawler import GameMonetizeEnhancedCrawler
import json
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_fixed_crawler():
    """æµ‹è¯•ä¿®å¤åçš„çˆ¬è™«"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•ä¿®å¤åçš„GameMonetizeå¢å¼ºçˆ¬è™«...")
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    crawler = GameMonetizeEnhancedCrawler()
    
    # è®¾ç½®æµ‹è¯•URL
    test_urls = [
        "https://gamemonetize.com/among-us-online-edition-game",
        "https://gamemonetize.com/ultimate-robot-fighting-game",
        "https://gamemonetize.com/construction-simulator-lite-game"
    ]
    
    if not crawler.setup_driver():
        print("âŒ æµè§ˆå™¨é©±åŠ¨åˆå§‹åŒ–å¤±è´¥")
        return False
    
    try:
        results = []
        
        for i, url in enumerate(test_urls, 1):
            print(f"\n{'='*60}")
            print(f"ğŸ® æµ‹è¯•æ¸¸æˆ {i}/{len(test_urls)}: {url}")
            print(f"{'='*60}")
            
            # æå–æ¸¸æˆä¿¡æ¯
            game_info = crawler.extract_complete_game_info(url)
            
            if game_info:
                results.append(game_info)
                
                # æ˜¾ç¤ºæå–ç»“æœ
                basic_info = game_info['basic_info']
                print(f"âœ… æ¸¸æˆåç§°: {basic_info['name']}")
                print(f"ğŸ“ æè¿°: {game_info['description'][:100]}..." if game_info['description'] else "âŒ æ— æè¿°")
                print(f"ğŸ·ï¸ æ ‡ç­¾: {', '.join(game_info['tags'])}" if game_info['tags'] else "âŒ æ— æ ‡ç­¾")
                print(f"ğŸ¯ è´¨é‡åˆ†: {game_info['quality_score']}")
                print(f"ğŸ–¼ï¸ ç¼©ç•¥å›¾: {len(game_info['thumbnails'])} å¼ ")
                print(f"ğŸ® iframe: {'âœ…' if game_info['iframe_info']['found'] else 'âŒ'}")
                
            else:
                print(f"âŒ æå–å¤±è´¥")
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        if results:
            test_file = "test_fixed_crawler_results.json"
            with open(test_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"\n{'='*80}")
            print(f"ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
            print(f"{'='*80}")
            print(f"æ€»æµ‹è¯•æ•°: {len(test_urls)}")
            print(f"æˆåŠŸæ•°: {len(results)}")
            print(f"æˆåŠŸç‡: {len(results)/len(test_urls)*100:.1f}%")
            
            # æ•°æ®å®Œæ•´æ€§åˆ†æ
            with_description = len([g for g in results if g['description']])
            with_tags = len([g for g in results if g['tags']])
            with_iframe = len([g for g in results if g['iframe_info']['found']])
            with_thumbnails = len([g for g in results if g['thumbnails']])
            
            print(f"\nğŸ“‹ æ•°æ®å®Œæ•´æ€§:")
            print(f"æœ‰æè¿°: {with_description}/{len(results)} ({with_description/len(results)*100:.1f}%)")
            print(f"æœ‰æ ‡ç­¾: {with_tags}/{len(results)} ({with_tags/len(results)*100:.1f}%)")
            print(f"æœ‰iframe: {with_iframe}/{len(results)} ({with_iframe/len(results)*100:.1f}%)")
            print(f"æœ‰ç¼©ç•¥å›¾: {with_thumbnails}/{len(results)} ({with_thumbnails/len(results)*100:.1f}%)")
            
            # è´¨é‡åˆ†æ
            quality_scores = [g['quality_score'] for g in results]
            avg_quality = sum(quality_scores) / len(quality_scores)
            print(f"\nğŸ¯ è´¨é‡åˆ†æ:")
            print(f"å¹³å‡è´¨é‡åˆ†: {avg_quality:.2f}")
            
            print(f"\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {test_file}")
            
            # æ£€æŸ¥ä¿®å¤æ•ˆæœ
            if with_description == len(results) and with_tags == len(results):
                print(f"\nğŸ‰ ä¿®å¤å®Œå…¨æˆåŠŸï¼æ‰€æœ‰æ¸¸æˆéƒ½æˆåŠŸæå–äº†æè¿°å’Œæ ‡ç­¾")
                return True
            elif with_description > 0 or with_tags > 0:
                print(f"\nâœ… ä¿®å¤éƒ¨åˆ†æˆåŠŸï¼æå–åˆ°äº†ä¸€äº›æè¿°å’Œæ ‡ç­¾")
                return True
            else:
                print(f"\nâŒ ä¿®å¤å¤±è´¥ï¼Œä»ç„¶æ— æ³•æå–æè¿°å’Œæ ‡ç­¾")
                return False
        else:
            print(f"\nâŒ æ‰€æœ‰æµ‹è¯•éƒ½å¤±è´¥äº†")
            return False
            
    finally:
        if crawler.driver:
            crawler.driver.quit()

def main():
    """ä¸»å‡½æ•°"""
    success = test_fixed_crawler()
    
    if success:
        print(f"\nğŸš€ ä¿®å¤éªŒè¯æˆåŠŸï¼å¯ä»¥å¼€å§‹é‡æ–°é‡‡é›†æ¸¸æˆæ•°æ®äº†")
        
        # è¯¢é—®æ˜¯å¦å¼€å§‹é‡æ–°é‡‡é›†
        print(f"\nğŸ’¡ å»ºè®®æ“ä½œ:")
        print(f"1. åˆ é™¤ä¹‹å‰çš„é‡‡é›†ç»“æœæ–‡ä»¶")
        print(f"2. é‡æ–°è¿è¡Œå¢å¼ºçˆ¬è™«é‡‡é›†500ä¸ªæ¸¸æˆ")
        print(f"3. ç”ŸæˆSEOæ–‡ä»¶")
        
    else:
        print(f"\nâŒ ä¿®å¤éªŒè¯å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")

if __name__ == "__main__":
    main() 